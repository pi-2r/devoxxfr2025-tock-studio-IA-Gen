#  Observabilit√©

[<img src="img/india-jones-crystal-skull.jpg"  alt="india-jones-crystal-skull">](https://www.youtube.com/watch?v=zc6Q_TNd5pA)

> "Follow the lines that only the gods can read that lead to Orellana's cradle.", Indiana Jones and the Kingdom of the Crystal Skull, Steven Spielberg, 2008
 
<br/>
<u>Objectifs:</u>

- D√©couvrir langfuse, cr√©ation d'un compte, projet et cl√© d'API
- Configurer langfuse dans Tock

## Sommaire

- [ Gen AI - Observability Settings](#gen-ai---observability-settings)
    - [Acc√©der √† Langfuse](#acc√©der-√†-langfuse)
    - [Cr√©er une nouvelle organisation](#cr√©er-une-nouvelle-organisation)
    - [Cr√©er un nouveau projet](#cr√©er-un-nouveau-projet)
    - [R√©cup√©rer les cl√©s d'API](#r√©cup√©rer-les-cl√©s-dapi)


- [Langfuse et Tock Studio](#langfuse-et-tock-studio)
    - [Connecter Tock Studio √† Langfuse](#connecter-tock-studio-√†-langfuse)
    - [Interroger le bot](#interroger-le-bot)
    - [g√©n√©rer des phrases d'entra√Ænement](#g√©n√©rer-des-phrases-dentra√Ænement)
    - [Voir les traces dans Langfuse](#voir-les-traces-dans-langfuse)



# Gen AI - Observability Settings

- L'observabilit√© des mod√®les de langage (LLM Observability) aide √† surveiller, d'analyser et de comprendre le comportement des mod√®les de langage √† grande √©chelle.
- Cela inclut la collecte de donn√©es sur leurs performances, la d√©tection d'anomalies et la compr√©hension des erreurs qu'ils peuvent produire.
- L'objectif est de garantir que ces mod√®les fonctionnent de mani√®re fiable, transparente, en fournissant des informations qui permettent d'am√©liorer leur performance et de corriger les probl√®mes potentiels.

## Docker, lancer le service langfuse

<details>
  <summary>Docker marche pas chez moi je suis sur tock.lan</summary>
  
  Vous pouvez utiliser le langfuse mutualis√© sur [http://tock.lan:3000](http://tock.lan:3000).
</details>

Dans le fichier `docker/docker-compose.yml` d√©commenter la block `langfuse-server:` et relancer un :
```bash
cd docker
source .env
docker compose -p devoxx_tock up -d
```

Vous devriez avoir ce r√©sultat :

<img src="img/result_langfuse_docker_compose.png" alt="resultat docker compose langfuse">


## Acc√©der √† Langfuse
Pour acc√©der √† la plateforme Langfuse, rendez √† l'adresse suivante http://localhost:3000/ ou sur http://tock.lan:3000 (si vous √™tes sur l'instance mutualis√©e).

<img src="img/langfuse.png" alt="langfuse">

L√† vous allez devoir cr√©er un acc√©s, en cliquant sur le bouton **Sign Up** vous allez √™tre redirig√© vers la page de cr√©ation de compte.

<img src="img/langfuse-create-account.png" alt="creation de compte">

<details>
  <summary>J'utilise le langfuse mutualis√© sur tock.lan</summary>
  
  Veuillez suivre les consignes suivantes :
  * Cr√©er un compte avec le m√™me identifiant que sur le Tock Studio (tock.lan)
  * Cr√©er une organisation avec pour nom d'organisation le nom de votre namespace sur Tock Studio
</details>

Dans notre cas, nous allons utiliser le login **admin**, l'email **admin@app.com** et le mot de passe **password** (ces √©l√©ments sont donn√©s √† titre d'exemple, vous pouvez utiliser les v√¥tres).
Une fois que vous avez rempli les champs, cliquez sur le bouton **Sign Up**.

## Cr√©er une nouvelle organisation

Une fois que vous avez cr√©√© votre compte, vous allez √™tre redirig√© vers la page principale de l‚Äôespace admin qui ressemble √† celle-ci.

<img src="img/langfuse-new-organisation.png" alt="nouvelle organisation">

L√† vous allez cliquer sur **New Organization**, et lui donner un nom. Dans notre cas, se sera **codelab-tock-2025** (ou votre nom de namespace si vous √™tes sur l'instance mutualis√©e), puis de cliquer sur **Create**.

Vous devriez voir votre nouvelle organisation apparaitre dans la liste des organisations, comme ci-dessous.

<img src="img/langfuse-finalize-organization.png" alt="nouvelle organisation">

Ensuite vous allez cliquer sur le bouton **Next**.

## Cr√©er un nouveau projet
L√† vous allez d√©finir le nom de votre nouveau projet. Dans notre cas, se sera **codelab-tock-project**, puis de cliquer sur **Create**.
Vous devriez voir une nouvelle page apparaitre avec les informations de votre projet.

<img src="img/langfuse-new-project-with-all-information.png" alt="nouveau projet">

## R√©cup√©rer les cl√©s d'API
Sur la page de votre projet, cliquer sur l‚Äôonglet API Keys, pour √™tre rediriger sur la page qui centralise toutes les 
cl√©s d‚Äôapi de votre projet. La liste √©tant vide, il faut cliquer sur le bouton **+ Create new API keys**.

<img src="img/langfuse-create-api-keys.png" alt="liste api keys">

D√®s lors, vous allez voir apparaitre une pop-up qui contient les listes d‚ÄôAPI-key, comme dans l‚Äôexemple suivant :

<img src="img/langfuse-new-api-keys.png" alt="nouvelle api key">

>Ne fermez pas cette pop-up car vous allez en avoir besoin pour connecter Tock √† Langfuse !


## Langfuse et Tock Studio

Dans cette partie, nous allons voir comment connecter Tock Studio √† Langfuse pour observer les performances du mod√®le.

### Interlude r√©seau

Avant de configurer Langfuse dans Tock Studio il est important de comprendre que langfuse va √™tre consomm√© / acc√©der
de 2 mani√®res diff√©rentes :
 * par l'orchestrateur Gen AI, composant docker-compose `gen_ai_orchestrator-server` qui ex√©cute la chaine RAG :
   * ceci √† lieu √† l'int√©rieur du r√©seau docker on pourra doc l'appeler via http://langfuse-server:3000 car il est
adress√© par ce nom au sein du r√©seau docker. On appellera cet acc√®s l'**URL priv√©e de langfuse**.
   * si vous utilisez l'instance partag√©e de Tock Studio, au sein de cette instance tourne la m√™me stack docker
   la configuration est donc identique.
 * par vous en tant qu'utilisateur, depuis l'ext√©rieur du r√©seau docker via http://localhost:3000 ou s'il s'agit du
langfuse partag√© via http://tock.lan:3000. On appellera cet acc√®s l'**URL publique de langfuse**.

Ce type de configuration est courrant si vous effectu√©e un d√©ploiement kube de Tock via
[tock-helm-chart](https://github.com/theopenconversationkit/tock-helm-chart) vous aurez aussi cette typologie
des trace qui remontent internes au cluster et un backoffice acc√©d√© par l'ext√©rieur.

```mermaid
flowchart TD
    subgraph "R√©seau Docker"
        Orchestrateur[<b>gen_ai_orchestrator-server</b><br>Gen AI Orchestrator]
        Langfuse[<b>langfuse-server</b><br>Langfuse Server<br/>]
        Orchestrateur -->|Acc√®s via URL priv√©e <br> http://langfuse-server:3000| Langfuse
    end

    Utilisateur["üë§ Admin Tock"]
    Utilisateur -->|Acc√®s via URL publique<br/>http://localhost:3000 ou http://tock.lan:3000| Langfuse
```

### Connecter Tock Studio √† Langfuse

Dans Tock Studio, allez dans le menu de gauche dans **Gen AI** > **Observability settings** pour arriver sur cette page


<img src="img/obersvability-settings.png" alt="tock obersvability settings">

Indiquez donc les valeurs suivantes pour les urls :
* Public Key : celle g√©n√©r√©e dans langfuse
* Secret Key : celle g√©n√©r√©e dans langfuse
* Url : il s'agit de l'url priv√©e `http://langfuse-server:3000`
* Url Public : `http://localhost:3000` OU si vous √™tes sur l'instance partag√©e `http://tock.lan:3000`.

‚ö†Ô∏è N'oubliez pas d'activer l'option **Observability activation** apr√®s avoir rempli les champs et sauvegarder les param√®tres.


### Interroger le bot
Pour tester la connexion entre Tock et Langfuse, vous allez interroger le bot avec une phrase d‚Äôexemple.
Dans le menu de gauche, allez dans **Bot** > **Test Bot** pour arriver sur cette page.

```bash
What is the Umbrella Academy ?
```

<img src="img/test_bot_for_langfuse.png" alt="test bot">

## Retrouver les traces depuis la vue Analytics > Dialogs

Chaque √©change avec les bot est historis√© et accesible depuis la vue Analytics > Dialogs.

Vous y retrouvez notamment un lien vers la trace langfuse associ√©e √† chaque message RAG g√©n√©r√© :
![Icon trace langfuse](img/observability_trace-link.excalidraw.png)

## Depuis le dashboard langfuse

Maintenant, allez sur tableau de bord de Langfuse (http://localhost:3000/) pour voir les traces.

<img src="img/langfuse-dashboard.png" alt="langfuse dashboard">

Dans le menu de gauche, allez dans **Tracing** > **Traces** pour arriver sur ce tableau.

<img src="img/langfuse-tracing.png" alt="langfuse tracing">

L√†, vous allez choisir l‚Äô√©l√©ment dont le nom contient **Sentence Generation**, cliquer sur l‚Äô**ID**de ce m√™me √©l√©ment 
et vous pourrez voir les d√©tails de la g√©n√©ration de phrases ou de mots de cette action.

<img src="img/langfuse-tracing-details.png" alt="langfuse tracing details">

> **Note :** Les √©l√©ments varient en fonction de la demande et du type de LLM qui est utilis√© pour produire un r√©sultat demand√©

Vous y retrouverez aussi les traces des chaines RAG, ce qui vous permet de voir les documents retrouv√©s cot√©s base documentaire, les diff√©rents prompts qui s'enchainent (effet m√©moire...).




## √âtape suivante

- [√âtape 9](step_9.md)
